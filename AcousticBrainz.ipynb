{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AcousticBrainz feature \n",
    "By Victor Badenas\n",
    "\n",
    "### Plotting and analysis of the most instantiated generes' features present in AllMusic, Discogs, LastFM and TagTraum\n",
    "\n",
    "First the environment is set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "IMAGE_FOLDER = os.path.join(os.path.abspath(\"\"),\"Output Plots\")\n",
    "DATA_FOLDER = os.path.join(os.path.abspath(\"\"), \"Data Files\")\n",
    "\n",
    "if not os.path.isdir(IMAGE_FOLDER): os.makedirs(IMAGE_FOLDER)\n",
    "if not os.path.isdir(DATA_FOLDER): os.makedirs(DATA_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Computing the Intersection\n",
    "\n",
    "### Load all four datasets\n",
    "\n",
    "Load them row by row using a reder object as we are only interested in the sound_id part and store the sound_id in a set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f09623164b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msound\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mallmusic_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mallmusic_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"recordingmbid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "allmusic_ids = set([])\n",
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-allmusic-train.tsv\")\n",
    "with open(file) as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for sound in reader:\n",
    "        allmusic_ids.add(sound[0])\n",
    "    allmusic_ids.discard(\"recordingmbid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discogs_ids = set([])\n",
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-discogs-train.tsv\") \n",
    "with open(file) as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for sound in reader:\n",
    "        discogs_ids.add(sound[0])\n",
    "    discogs_ids.discard(\"recordingmbid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lastfm_ids = set([])\n",
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train.tsv\") \n",
    "with open(file) as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for sound in reader:\n",
    "        lastfm_ids.add(sound[0])\n",
    "    lastfm_ids.discard(\"recordingmbid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tagtraum_ids = set([])\n",
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-tagtraum-train.tsv\") \n",
    "with open(file) as tsvfile:\n",
    "    reader = csv.reader(tsvfile, delimiter='\\t')\n",
    "    for sound in reader:\n",
    "        tagtraum_ids.add(sound[0])\n",
    "    tagtraum_ids.discard(\"recordingmbid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the intersection for the ids of all four datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "intersection_ids = allmusic_ids & discogs_ids & lastfm_ids & tagtraum_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(intersection_ids))\n",
    "intersection_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Get only one database and get the intersection info\n",
    "\n",
    "### Load the LastFM dataset\n",
    "\n",
    "Loading it as a pandas matrix and then compute the difference between the whole dataset and the intersection so that we are left only with the information of the intersection_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train.tsv\") \n",
    "with open(file) as tsvfile:\n",
    "    lastfm_sounds = pd.read_csv(file,sep='\\t',index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the items in the dataframe that are not in the intersection set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff = set(lastfm_sounds.index.tolist())-intersection_ids\n",
    "lastfm_sounds = lastfm_sounds.drop(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lastfm_sounds.shape)\n",
    "lastfm_sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the intersection pandas dataframe to a tsv for the lines above to be only computed once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train-intersection.tsv\")\n",
    "with open(file,\"w\") as tsvfile:\n",
    "    lastfm_sounds.to_csv(tsvfile,sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load if the intersection has already been computed and stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train-intersection.tsv\")\n",
    "with open(file) as tsvfile:\n",
    "    lastfm_sounds = pd.read_csv(tsvfile,sep = '\\t',index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Reducing the dataset to the most occurrent\n",
    "\n",
    "### Shortening the pandas matrix to the sounds with most frequent generes\n",
    "\n",
    "First we do a counter for the generes and store it in a default_dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get names of the columns (genre1, genre2, etc...)\n",
    "col_names = list(lastfm_sounds)\n",
    "\n",
    "#declare counter default dictionary\n",
    "genere_counter = defaultdict(int)\n",
    "\n",
    "#iterate through genre columns\n",
    "for col in col_names[1:]:\n",
    "    \n",
    "    #for each column, get the list of that column's values for all sound_ids\n",
    "    col_values = lastfm_sounds[col].tolist()\n",
    "    \n",
    "    #iterate in that list\n",
    "    for genere in col_values:\n",
    "        \n",
    "        #if the genre has a subgenre, it will be of the format genre---subgenre, if it does not have a subgenre, ignore\n",
    "        try:\n",
    "            subgenere = genere.split(\"---\")[1]\n",
    "        except(AttributeError,IndexError) as e:\n",
    "            subgenere = ''\n",
    "        if subgenere != '' : genere_counter[genere] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the N most frequent subgeneres are gotten and converted it to a list of genre---subgenre "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "N = 20 #how many genres to consider\n",
    "\n",
    "#create dataframe for the default dictionary containing {Genere:Times it is mentioned}\n",
    "generespd = pd.DataFrame(list(genere_counter.items()))\n",
    "\n",
    "#change dataframe's column and row values\n",
    "generespd.columns = [\"Genere\",\"Count\"]\n",
    "generespd = generespd.set_index(\"Genere\")\n",
    "\n",
    "#get only the N largest in the Count column\n",
    "generespd = generespd.nlargest(N, \"Count\")\n",
    "\n",
    "#convert the index to list in order to compare further on\n",
    "most_frequent = generespd.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only the sounds that have the most_frequent subgenres in the generes matrix and delete the generes that are not on the list even if the sound has one of the most_frequent subgeneres, as the subgeneres that are not in the list are not relevant for the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make a copy of lastfm_sounds as pandas works by reference by default\n",
    "lastfm_sounds_intersected_N = lastfm_sounds.copy() \n",
    "\n",
    "#iterate through the columns\n",
    "for col in lastfm_sounds:\n",
    "    \n",
    "    #check for all the genres in most frequent and replace anything that is not there with a Nan\n",
    "    lastfm_sounds_intersected_N[col] = lastfm_sounds[col].str.extract(r\"\\b^(\"+\"|\".join(most_frequent)+r\")\\b\")\n",
    "    \n",
    "#Delete all rows and columns filled exclusively with Nan\n",
    "lastfm_sounds_intersected_N = lastfm_sounds_intersected_N.dropna(how='all').dropna(axis='columns',how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(lastfm_sounds_intersected_N.shape)\n",
    "lastfm_sounds_intersected_N.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the values of the matrix that has the N most frequent generes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train-intersection-20.tsv\")\n",
    "with open(file,\"w\") as tsvfile:\n",
    "    lastfm_sounds_intersected_N.to_csv(tsvfile,sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open the file if the code above has already been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-lastfm-train-intersection-20.tsv\")\n",
    "with open(file) as tsvfile:\n",
    "    lastfm_sounds_intersected_N = pd.read_csv(tsvfile,sep = '\\t',index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Prepare the features' data to be plotted \n",
    "\n",
    "### Open csv Files with the Features\n",
    "\n",
    "After this, load the csv file with the features ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval2017-train-amplab2019-selected-features-mbid.csv\")\n",
    "with open(file) as csvfile:\n",
    "    selected_features = pd.read_csv(csvfile,index_col = 0, low_memory = False)\n",
    "selected_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and compute the difference as it is done in the LoadFM dataset part, to drop the files that are not in the list of the sounds containing the N most frequent subgeneres:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "diff_features = set(selected_features.index.tolist())-set(lastfm_sounds_intersected_N.index.tolist())\n",
    "selected_features = selected_features.drop(diff_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_features.shape)\n",
    "selected_features.sort_index().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Plot of the features by genre \n",
    "\n",
    "### Computation of the features in a dictionary of genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#initialize dictionary\n",
    "information = {}\n",
    "\n",
    "#loop through subgenres to create an entry in the dictionary for each subgenre where in each entry, a dictionary of\n",
    "#the features will be created in order to get a dictionary of features for each genre in an organised manner.\n",
    "for i,sub_genre in enumerate(most_frequent):\n",
    "    \n",
    "    print(\"Processing {0} out of {1}\".format(i+1,len(most_frequent)))\n",
    "    \n",
    "    #temporal variable that copies the lastfm intersected N pandas matrix\n",
    "    lastfm_sounds_intersected_N_temp = lastfm_sounds_intersected_N.copy()\n",
    "\n",
    "    #iterate through columns for:\n",
    "    #- All genres that are not the one in each iteration will be repaced with NaN\n",
    "    #- All columns and sound ids that are not from that genere get deleted\n",
    "    for col in lastfm_sounds_intersected_N_temp:\n",
    "        \n",
    "        lastfm_sounds_intersected_N_temp[col] = lastfm_sounds_intersected_N_temp[col].str.extract(r\"\\b^(\"+sub_genre+r\")\\b\")\n",
    "\n",
    "    lastfm_sounds_intersected_N_temp = lastfm_sounds_intersected_N_temp.dropna(how='all').dropna(how='all',axis='columns')\n",
    "    \n",
    "    #initializing the features dictionary for each subgenre\n",
    "    information[sub_genre] = {}\n",
    "    \n",
    "    #for each feature, add the list features for each subgenre to the dictionary\n",
    "    for feature in list(selected_features):\n",
    "        \n",
    "        #get only the feature that it's wanted\n",
    "        temp = selected_features[feature].to_frame()\n",
    "        \n",
    "        #get only the information for the genre for this iteration\n",
    "        temp = temp.drop(set(temp.index.tolist())-set(lastfm_sounds_intersected_N_temp.index.tolist()))\n",
    "        \n",
    "        #add entry to the dictionary\n",
    "        information[sub_genre].update({ feature : temp[feature].tolist() })\n",
    "    \n",
    "    clear_output()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of the features distribution\n",
    "\n",
    "Once the dictionary containing all features for all subgenres as a 3D matrix or dictionary (subgenre,feature,data) the plot is computed from this hirearchy.\n",
    "\n",
    "First, functions for plotting the barplot from a dictionary that contains the number of times a discrete feature ocurrs is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotbar(feature_name,counter,percentage,directory):\n",
    "    \n",
    "    file = os.path.join(directory,\"{}.{}\".format(feature_name,'png'))\n",
    "    \n",
    "    #initialize plot and axes objects\n",
    "    fig, ax = plt.subplots()\n",
    "    opacity = 0.8\n",
    "    \n",
    "    #get the strings for the features that will be on the legend.\n",
    "    indexes_str = list(counter[list(counter.keys())[0]].keys())\n",
    "    \n",
    "    #get the genre strings and ints(for multibar plot purposes)\n",
    "    genre_index_int = np.arange(len(list(counter.keys())))\n",
    "    genre_index_str = list(counter.keys())\n",
    "    \n",
    "    #set the value of the bar width according to the number of bar that have to be plotted in each x value\n",
    "    bar_width = 1/(1.25*len(indexes_str))\n",
    "    \n",
    "    #for multibar plot purposes\n",
    "    i = 0\n",
    "    \n",
    "    #calculate the sum of values for each subgenre in order to normalize if desired\n",
    "    norm_array = [] \n",
    "    for sub_genre in genre_index_str:\n",
    "        norm = 0\n",
    "        for index in indexes_str:\n",
    "            norm += counter[sub_genre][index]\n",
    "        norm_array.append(norm)\n",
    "    \n",
    "    #for each value of the legend:\n",
    "    for index in indexes_str:\n",
    "        \n",
    "        #list of values to print\n",
    "        val = []\n",
    "        \n",
    "        #for each value in x axis\n",
    "        for sub_genre in counter.keys():\n",
    "            \n",
    "            #add the corresponding value to the list\n",
    "            val.append(counter[sub_genre][index])\n",
    "            \n",
    "        if percentage:\n",
    "            val[:] = [100*x/norm for x,norm in zip(val,norm_array)]\n",
    "        \n",
    "        #print the rectangle\n",
    "        rects1 = plt.bar(genre_index_int + i*bar_width, val, bar_width, alpha=opacity, label=index)\n",
    "        \n",
    "        #for multibar plot purposes\n",
    "        i += 1\n",
    "        \n",
    "\n",
    "    plt.xlabel('Genre')\n",
    "    if percentage:\n",
    "        plt.ylabel('Percentage')\n",
    "    else:\n",
    "        plt.ylabel('Appearances')\n",
    "    plt.title(feature_name)\n",
    "    plt.xticks(genre_index_int + i/2*bar_width, genre_index_str )\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(),rotation=45,ha=\"right\")\n",
    "    plt.legend()\n",
    "    fig.set_size_inches(15,10)\n",
    "    plt.savefig(file, dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function for the boxplot given a list of arrays of data and a list of labels, do an horizontal plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotbox(feature_name,list_data,list_names,directory):\n",
    "    \n",
    "    file = os.path.join(directory,\"{}.{}\".format(feature_name,'png'))\n",
    "    \n",
    "    #initalize figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    #set title\n",
    "    ax.set_title(feature_name)\n",
    "    \n",
    "    #plot the data with the list given horizontally\n",
    "    ax.boxplot(list_data,labels=list_names,vert=False)\n",
    "    \n",
    "    fig.set_size_inches(15,10)\n",
    "    plt.savefig(file, dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do one plot or the other depending on the feature to plot. \n",
    "\n",
    "It is also saved a png image of the plot to an output image folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loop though the features\n",
    "for i,feature in enumerate(list(selected_features)):\n",
    "    \n",
    "    print(\"Processing {0} out of {1}\".format(i+1,len(most_frequent)))\n",
    "    \n",
    "    #if the feature selected is the tonal key or the tonal scale:\n",
    "    #- loop for each subgenre\n",
    "    #- count the times a feature is repeated for each genre\n",
    "    #- call plotbar function\n",
    "    if (feature == 'tonal.key_key') | (feature == 'tonal.key_scale'):\n",
    "        counter = {}\n",
    "        for sub_genre in most_frequent:\n",
    "            counter[sub_genre] = defaultdict(int)\n",
    "            str_list = information[sub_genre][feature]\n",
    "            for item in str_list:\n",
    "                counter[sub_genre][item] += 1\n",
    "        plotbar( feature_name = feature, counter = counter,percentage = True, directory = IMAGE_FOLDER)\n",
    "    \n",
    "    #if the feature is any other:\n",
    "    #- get the data and store it in a list of arrays of data synced with the most_frequent features labels\n",
    "    #- call plotbox function\n",
    "    else:\n",
    "        list_data = []\n",
    "        list_names = most_frequent\n",
    "        for sub_genre in most_frequent:\n",
    "            list_data.append(information[sub_genre][feature])\n",
    "        \n",
    "        plotbox( feature_name=feature, list_data=list_data, list_names=list_names, directory = IMAGE_FOLDER)\n",
    "        \n",
    "    clear_output()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 6: Plot of High-Level data\n",
    "\n",
    "The code below performs a scan of files through the folder containing the high level features and it stores the features as follows:\n",
    "- indexes are mbid\n",
    "- each column is the feature\n",
    "- it has already checked that ids of the files are in the selected_features as well so that we don't waste resources on this.\n",
    "\n",
    "## DISCLAIMER: this takes a long time (around 1h15 in an i7-6700HQ) if some other genere selection method wants to be used this part must be executed again if the same selection method wants to be done, just skip this cell and load the tsv file from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features_to_extract_from_json = [ \"aggressive\", \"happy\", \"sad\", \"party\", \"relaxed\",\"instrumental\", \"voice\", \"female\", \"male\"]\n",
    "\n",
    "labels_to_extract = [\"mood_aggressive\",\"mood_happy\",\"mood_sad\",\"mood_party\",\"mood_relaxed\",\"voice_instrumental\", \"voice_instrumental\", \"gender\", \"gender\"] \n",
    "\n",
    "#print(features_to_extract_from_json,labels_to_extract)\n",
    "sound_id_highlevel = selected_features.index.tolist()\n",
    "\n",
    "folder_highlevel_features = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval-train-intersection-highlevel\")\n",
    "\n",
    "highlevel_features = pd.DataFrame(columns = features_to_extract_from_json)\n",
    "\n",
    "numfolders = sum([1 for _, _, _ in os.walk(folder_highlevel_features)])\n",
    "i = 1\n",
    "\n",
    "for subdir, _, files in os.walk(folder_highlevel_features):\n",
    "    \n",
    "    starttime = time.clock()\n",
    "    print(\"{}/{}\".format(str(i),str(numfolders)))\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        filename, file_extension = os.path.splitext(file)\n",
    "        \n",
    "        file_absolute_path = os.path.join(subdir,file)\n",
    "        \n",
    "        if file_extension == \".json\":\n",
    "            \n",
    "            if any(filename in s for s in sound_id_highlevel):\n",
    "                \n",
    "                temp_dict = {}\n",
    "                temp_dict[\"mbid\"] = filename\n",
    "                \n",
    "                with open(file_absolute_path) as jsonfile:\n",
    "                    json_dict = json.load(jsonfile)\n",
    "                    \n",
    "                json_dict = json_dict[\"highlevel\"]\n",
    "                for label,feature in zip(labels_to_extract,features_to_extract_from_json):\n",
    "                    temp_dict[feature] = json_dict[label][\"all\"][feature]\n",
    "                    \n",
    "                temp_dataframe = pd.DataFrame(temp_dict,index=[0])\n",
    "                highlevel_features = pd.concat([highlevel_features,temp_dataframe],ignore_index = True,sort = True)\n",
    "    \n",
    "    time_expected = (time.clock()-starttime)*(numfolders-i)\n",
    "    print(str(time_expected))\n",
    "    i += 1\n",
    "highlevel_features = highlevel_features.set_index(\"mbid\").sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the highlevel_features to a tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval-train-intersection-highlevel-selectedfeatures.tsv\")\n",
    "with open(file,\"w\") as tsvfile:\n",
    "    highlevel_features.to_csv(tsvfile,sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the highlevel_features from a tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(DATA_FOLDER,\"acousticbrainz-mediaeval-train-intersection-highlevel-selectedfeatures.tsv\")\n",
    "with open(file) as tsvfile:\n",
    "    highlevel_features = pd.read_csv(tsvfile,sep = '\\t',index_col=0,low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computation of the features in a dictionary of genres as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize dictionary\n",
    "information_highlevel = {}\n",
    "\n",
    "#loop through subgenres to create an entry in the dictionary for each subgenre where in each entry, a dictionary of\n",
    "#the features will be created in order to get a dictionary of features for each genre in an organised manner.\n",
    "for i,sub_genre in enumerate(most_frequent):\n",
    "    \n",
    "    print(\"Processing {0} out of {1}\".format(i+1,len(most_frequent)))\n",
    "    \n",
    "    #temporal variable that copies the lastfm intersected N pandas matrix\n",
    "    lastfm_sounds_intersected_N_temp = lastfm_sounds_intersected_N.copy()\n",
    "\n",
    "    #iterate through columns for:\n",
    "    #- All genres that are not the one in each iteration will be repaced with NaN\n",
    "    #- All columns and sound ids that are not from that genere get deleted\n",
    "    for col in lastfm_sounds_intersected_N_temp:\n",
    "        \n",
    "        lastfm_sounds_intersected_N_temp[col] = lastfm_sounds_intersected_N_temp[col].str.extract(r\"\\b^(\"+sub_genre+r\")\\b\")\n",
    "\n",
    "    lastfm_sounds_intersected_N_temp = lastfm_sounds_intersected_N_temp.dropna(how='all').dropna(how='all',axis='columns')\n",
    "    \n",
    "    #initializing the features dictionary for each subgenre\n",
    "    information_highlevel[sub_genre] = {}\n",
    "    \n",
    "    #for each feature, add the list features for each subgenre to the dictionary\n",
    "    for feature in list(highlevel_features):\n",
    "        \n",
    "        #get only the feature that it's wanted\n",
    "        temp = highlevel_features[feature].to_frame()\n",
    "        \n",
    "        #get only the information_highlevel for the genre for this iteration\n",
    "        temp = temp.drop(set(temp.index.tolist())-set(lastfm_sounds_intersected_N_temp.index.tolist()))\n",
    "        \n",
    "        #add entry to the dictionary\n",
    "        information_highlevel[sub_genre].update({ feature : temp[feature].tolist() })\n",
    "\n",
    "    clear_output()\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in list(highlevel_features):\n",
    "    \n",
    "    #- get the data and store it in a list of arrays of data synced with the most_frequent features labels\n",
    "    #- call plotbox function\n",
    "    list_data = []\n",
    "    list_names = most_frequent\n",
    "    for sub_genre in most_frequent:\n",
    "        list_data.append(information_highlevel[sub_genre][feature])\n",
    "\n",
    "    plotbox( feature_name=feature, list_data=list_data, list_names=list_names, directory = IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now the same is done for instrumental voice female and male features\n",
    "\n",
    "Same procedure as before: scan all the json files searching for the features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
